{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsv with boundaries locations\n",
    "tsv_file = \"./input_data/TAD_boundaries/boundaries_no_strong_CTCF.tsv\"\n",
    "# tsv_file = \"./input_data/TAD_boundaries/boundaries_strong_CTCFs.tsv\"\n",
    "\n",
    "# table with chromosome sizes\n",
    "chrom_sizes = \"/project/fudenber_735/genomes/mm10/mm10.fa.sizes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_sizes_table = pd.read_csv(chrom_sizes, sep=\"\\t\", names=[\"chrom\", \"size\"])\n",
    "\n",
    "seq_coords_df = pd.read_csv(tsv_file, sep=\"\\t\", index_col=None)\n",
    "seq_coords_df = seq_coords_df.loc[:, ~seq_coords_df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_coords_df = pd.read_csv(tsv_file, sep=\"\\t\", index_col=None)\n",
    "seq_coords_df = seq_coords_df.loc[:, ~seq_coords_df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the TAD boundaries are 10kb-long\n",
    "# for the comparisson purposes, let's center all the prediction windows on the TAD boundaries\n",
    "\n",
    "seq_length = 1310720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_tad_start = int((((seq_length / 2) - 5000) // 2048) * 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's approximate 4.88 bins as 5 bins\n",
    "\n",
    "rel_tad_end = rel_tad_start + 2048*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_window_end = seq_length - rel_tad_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_coords_df[\"window_start\"] = seq_coords_df[\"start\"] - rel_tad_start\n",
    "seq_coords_df[\"window_end\"] = seq_coords_df[\"start\"] + to_window_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking if we didn't get outside of chromosomes\n",
    "len(seq_coords_df[seq_coords_df[\"window_start\"] <= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_chrom = seq_coords_df.groupby(by=\"chrom\")[\"window_end\"].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in check_chrom.iterrows():\n",
    "    chr_size = int(\n",
    "        chrom_sizes_table.loc[\n",
    "            chrom_sizes_table[\"chrom\"] == row.chrom, \"size\"\n",
    "        ].iloc[0]\n",
    "    )\n",
    "    if chr_size < row.window_end:\n",
    "        print(\"problem\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_down_dfs = []\n",
    "\n",
    "# Loop through each bin (from down_20 to down_1)\n",
    "for i in range(1, 21):\n",
    "    # Create a temporary dataframe for each \"down\" bin\n",
    "    temp_df = seq_coords_df[[\"chrom\", \"start\", \"end\", \"window_start\", \"window_end\"]].copy()\n",
    "    temp_df[\"rel_disruption_start\"] = [(rel_tad_start - i*2048) for _ in range(len(temp_df))]\n",
    "    temp_df[\"rel_disruption_end\"] = [(rel_tad_start - (i-1)*2048) for _ in range(len(temp_df))]\n",
    "    temp_df[\"type\"] = [f\"down{i}\" for _ in range(len(temp_df))]\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    all_down_dfs.append(temp_df)\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "combined_down_df = pd.concat(all_down_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_dfs = []\n",
    "\n",
    "# Loop through each TAD bin (from tad1 to tad5)\n",
    "for i in range(5):  # This will loop from 0 to 4 for tad1 to tad5\n",
    "    # Create a temporary dataframe for each TAD bin\n",
    "    temp_df = seq_coords_df[[\"chrom\", \"start\", \"end\", \"window_start\", \"window_end\"]].copy()\n",
    "    temp_df[\"rel_disruption_start\"] = [rel_tad_start + (i * 2048) for _ in range(len(temp_df))]\n",
    "    temp_df[\"rel_disruption_end\"] = [rel_tad_start + ((i + 1) * 2048) for _ in range(len(temp_df))]\n",
    "    temp_df[\"type\"] = [f\"tad{i + 1}\" for _ in range(len(temp_df))]\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    tad_dfs.append(temp_df)\n",
    "\n",
    "# Concatenate all TAD dataframes into one\n",
    "combined_tad_df = pd.concat(tad_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_dfs = []\n",
    "\n",
    "# Loop through each UP bin (from up1 to up20)\n",
    "for i in range(1, 21):  # This will loop from 1 to 20 for up1 to up20\n",
    "    # Create a temporary dataframe for each UP bin\n",
    "    temp_df = seq_coords_df[[\"chrom\", \"start\", \"end\", \"window_start\", \"window_end\"]].copy()\n",
    "    temp_df[\"rel_disruption_start\"] = [rel_tad_end + (i - 1) * 2048 for _ in range(len(temp_df))]\n",
    "    temp_df[\"rel_disruption_end\"] = [rel_tad_end + i * 2048 for _ in range(len(temp_df))]\n",
    "    temp_df[\"type\"] = [f\"up{i}\" for _ in range(len(temp_df))]\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    up_dfs.append(temp_df)\n",
    "\n",
    "# Concatenate all UP dataframes into one\n",
    "combined_up_df = pd.concat(up_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([combined_down_df, combined_tad_df, combined_up_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concatenated.to_csv(\"boundaries_disruption_4.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basenji_py3.9_tf2.15",
   "language": "python",
   "name": "basenji_py3.9_tf2.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
